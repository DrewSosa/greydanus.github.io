I"–<div class="imgcap" style="display: block; margin-left: auto; margin-right: auto; width:99.9%">
  <div style="width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;padding-right:10px;">
    <video id="video_rose1" style="width:100%;min-width:250px;">
      <source src="/assets/nca-flowers/rose.mp4" type="video/mp4" />
    </video>
    <button class="playbutton" id="video_rose1_button" onclick="playPauseRose1()">Play</button> 
    <div style="text-align: left;margin-left:10px;margin-right:10px;">Using model-based planning to play billiards. The goal is to impart the tan cue ball with an initial velocity so as to move the blue ball to the black target.</div>
  </div>
  <div style="width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;padding-right:10px;">
    <video id="video_rose2" style="width:100%;min-width:250px;">
      <source src="/assets/nca-flowers/rose.mp4" type="video/mp4" />
    </video>
    <button class="playbutton" id="video_rose2_button" onclick="playPauseRose2()">Play</button> 
    <div style="text-align:left;margin-left:10px;margin-right:10px;">A baseline RNN trained on billiards dynamics can also be used for model-based planning. It's inefficient because it has to "tick" at a constant rate.</div>
  </div>
   <div style="width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;">
    <video id="video_rose3" style="width:100%;min-width:250px;">
      <source src="/assets/nca-flowers/rose3.mp4" type="video/mp4" />
    </video>
    <button class="playbutton" id="video_rose3_button" onclick="playPauseRose3()">Play</button> 
    <div style="text-align:left;margin-left:10px;margin-right:10px;">By contrast, a Jumpy RNN trained on the same task can perform planning in many fewer steps by jumping over spans of time where motion is predictable.</div>
  </div>
</div>

<script> 
function playPauseRose1() { 
  var video = document.getElementById("video_rose1"); 
  var button = document.getElementById("video_rose1_button");
  if (video.paused) {
    video.play();
  button.textContent = "Pause";}
  else {
    video.pause(); 
  button.textContent = "Play";}
} 

function playPauseRose2() { 
  var video = document.getElementById("video_rose2"); 
  var button = document.getElementById("video_rose2_button");
  if (video.paused) {
    video.play();
  button.textContent = "Pause";}
  else {
    video.pause(); 
  button.textContent = "Play";}
} 

function playPauseRose3() { 
  var video = document.getElementById("video_rose3"); 
  var button = document.getElementById("video_rose3_button");
  if (video.paused) {
    video.play();
  button.textContent = "Pause";}
  else {
    video.pause(); 
  button.textContent = "Play";}
} 
</script>

<div style="display: block; margin-left: auto; margin-right: auto; width:100%; text-align:center;">
  <a href="" id="linkbutton" target="_blank">Read the paper</a>
  <a href="" id="linkbutton" target="_blank"><span class="colab-span">Run</span> in browser</a>
  <a href="https://github.com/greydanus" id="linkbutton" target="_blank">Get the code</a>
</div>

<h2 id="closing-thoughts">Closing thoughts</h2>

<p>There is a counterintuitive possibility that in order to explore the limits of how large we can scale neural networks, we may need to explore the limits of how small we can scale them first. Scaling models and datasets downward in a way that preserves the nuances of their behaviors at scale will allow researchers to iterate quickly on fundamental and creative ideas. This fast iteration cycle is the best way of obtaining insights about how to incorporate progressively more complex inductive biases into our models. We can then transfer these inductive biases across spatial scales in order to dramatically improve the sample efficiency and generalization properties of large-scale models. We see the humble MNIST-1D dataset as a first step in that direction.</p>

<h2 id="footnotes">Footnotes</h2>
:ET